{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81b499ab-d128-4fcd-aef3-81cf659c4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from tqdm.auto import trange\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe0271b-9e4e-49c7-a488-700bf95f7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = \"cointegrated/rut5-base-multitask\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(name_model)\n",
    "tokenizer = T5Tokenizer.from_pretrained(name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddd76b4-a4f2-411c-8229-c2207837c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text, **kwargs):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        hypotheses = model.generate(**inputs, num_beams=5, **kwargs)\n",
    "    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-consumer",
   "metadata": {},
   "source": [
    "Read the list of file lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "595329c9-f8b6-4413-92b9-cc7cb46764d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list(file_name):\n",
    "    with open (file_name, 'r', encoding='utf-8') as f:\n",
    "        line = f.read()   \n",
    "    return line.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb018b19-287e-4755-8c5c-7ab2cb359b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954 954\n"
     ]
    }
   ],
   "source": [
    "Q9 = read_list('Q9.txt')\n",
    "A9 = read_list('A9.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b787845-dd49-4404-841d-67f499358ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = []\n",
    "for i in range(len(Q9)):\n",
    "    q = Q9[i]\n",
    "    a = A9[i]\n",
    "    QA += [[q, a]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b40ca67-34f9-4876-b9e7-36ed8c309ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954 954 954\n"
     ]
    }
   ],
   "source": [
    "print(len(Q9), len(A9), len(QA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-input",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f964b712-5872-478e-9112-a6fa89e8b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = QA\n",
    "\n",
    "batch_size = 4  # сколько примеров показываем модели за один шаг\n",
    "report_steps = 100  # раз в сколько шагов печатаем результат\n",
    "epochs = 6  # сколько раз мы покажем данные модели\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3cab372-2728-432a-800f-35bbc4f80f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6498a2ab684c17aeb13314c468ab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 3.972487688064575\n",
      "step 100 loss 3.117737009525299\n",
      "step 200 loss 3.0479803824424745\n",
      "EPOCH 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76839ea2256249409df582b3450e6a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.9752501964569094\n",
      "step 100 loss 2.9333178544044496\n",
      "step 200 loss 2.8076193034648895\n",
      "EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6924d0f6b6e24039a40a6551890fff96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.746127222776413\n",
      "step 100 loss 2.6386316442489623\n",
      "step 200 loss 2.6996596097946166\n",
      "EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7234f6c4c3ec41f99be40a34f503377a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.737358478307724\n",
      "step 100 loss 2.5827356243133544\n",
      "step 200 loss 2.4595706629753114\n",
      "EPOCH 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770321abf9674fd6b0efb47e30f5a228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.511818298101425\n",
      "step 100 loss 2.476200841665268\n",
      "step 200 loss 2.475251042842865\n",
      "EPOCH 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07c8fcf497b43f8b8816820da5aa5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.506560516357422\n",
      "step 100 loss 2.469781070947647\n",
      "step 200 loss 2.33880824804306\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    print('EPOCH', epoch)\n",
    "    random.shuffle(pairs)\n",
    "    for i in trange(0, int(len(pairs) / batch_size)):\n",
    "        batch = pairs[i * batch_size: (i + 1) * batch_size]\n",
    "        # encode the question and answer  \n",
    "        x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "        y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "        # -100 - a special value that allows you to ignore tokens\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        # calculate the loss function\n",
    "        loss = model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        # do a step of gradient descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        if i % report_steps == 0:\n",
    "            print('step', i, 'loss', np.mean(losses[-report_steps:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d030d87-b848-4908-8a61-2a068cebd013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rut51\\\\tokenizer_config.json',\n",
       " 'rut51\\\\special_tokens_map.json',\n",
       " 'rut51\\\\spiece.model',\n",
       " 'rut51\\\\added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name = 'rut51'  # name of the folder to save\n",
    "model.save_pretrained(new_model_name)\n",
    "tokenizer.save_pretrained(new_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-associate",
   "metadata": {},
   "source": [
    "## Eval the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85173f56-39ca-4993-aaef-15696cf53ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "def answer(x, **kwargs):\n",
    "    inputs = tokenizer(x, return_tensors='pt').to(model.device)\n",
    "    with torch.no_grad():\n",
    "        hypotheses = model.generate(**inputs, **kwargs)\n",
    "    return tokenizer.decode(hypotheses[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bc196fd-1347-4da4-846a-779a99f501fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Зачет принят.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer('Спасибо большое что дали настолько много времени, я успешно завершил зачёт')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a288c36-c4d6-4a57-9c3f-a6f71d126c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Да, доступ будет.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer('Писала Вам по поводу доступа на курсы на openedu. Отправляла две почты, на которые регестрировалась. Доступ так не получила. Окончательная почта, на которую зарегестрировалась - Очень прошу помочь с доступом на курсы!С Уважением,Рягузова МаргаритаМагистр ИТМО, Управление качеством.Отправлено через meizu X8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d45aed6-54b8-4e11-8589-3e3bcda7924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ожидайте уведомления о консультации.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer('Какой период обучения у потока ЦКМ 3? ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-publisher",
   "metadata": {},
   "source": [
    "Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b703b287-bc78-45b0-9a7b-d91008b2efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "path = 'rut51'\n",
    "tokenizer51 = T5Tokenizer.from_pretrained(path)\n",
    "print(type(tokenizer51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45a310dd-84c6-4df2-8d66-f57d1af17a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "model51 = T5ForConditionalGeneration.from_pretrained(path)\n",
    "print(type(model51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "91b460e2-4785-46cc-86e9-205e435d3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model51.eval()\n",
    "def answer51(x, **kwargs):\n",
    "    inputs = tokenizer51(x, return_tensors='pt').to(model51.device)\n",
    "    print(inputs)\n",
    "    print(inputs['input_ids'].shape)\n",
    "    with torch.no_grad():\n",
    "        hypotheses = model51.generate(**inputs, **kwargs)\n",
    "    return tokenizer51.decode(hypotheses[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f0c6dcd0-b9d4-4fca-9024-3e74eb6691cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 1152,  5713,  1164, 14656,   396,  9278,  5851, 19988,  6331,  2895,\n",
      "           315,   259, 20218,  1400,   353,   261,   425, 10257,  1291, 16383,\n",
      "          5822,   310,  2031, 22585,   456, 17418,  3423,  7455,   259, 16572,\n",
      "           308,  1306,  6404, 12554, 18177,   260,  1602,  9248,  2244, 11522,\n",
      "          1195,   261,   733,  2660,  2660,   261,   259, 17402,   688,  2309,\n",
      "          1850,   264,   264,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "torch.Size([1, 54])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Зачет принят.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer51('По предметам модуля цифровая культура записана в поток 4.1, по ошибке зарегистрировалась на экзамен утром 23.09. Хотела бы отменить запись.Афонина Виктория, 309898, группа С4106--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
